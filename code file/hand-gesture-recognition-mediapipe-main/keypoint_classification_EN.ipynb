{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
        "model_save_path = 'hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5'\n",
        "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 5"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xQU7JTZ_9hE0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Input((21 * 2, )),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(20, activation='relu'),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Dense(10, activation='relu'),\n",
        "    keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqky9tc9hE1",
        "outputId": "5db082bb-30e3-4110-bf63-a1ee777ecd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 42)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                860       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,125\n",
            "Trainable params: 1,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MbMjOflQ9hE1"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c3Dac0M_9hE2"
      },
      "outputs": [],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7XI0j1Iu9hE2"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WirBl-JE9hE3",
        "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            " 1/33 [..............................] - ETA: 18s - loss: 1.6725 - accuracy: 0.2344\n",
            "Epoch 1: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 1s 6ms/step - loss: 1.6177 - accuracy: 0.2187 - val_loss: 1.5354 - val_accuracy: 0.2735\n",
            "Epoch 2/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.5548 - accuracy: 0.2422\n",
            "Epoch 2: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.5367 - accuracy: 0.3020 - val_loss: 1.4641 - val_accuracy: 0.3898\n",
            "Epoch 3/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.4900 - accuracy: 0.3594\n",
            "Epoch 3: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.4903 - accuracy: 0.3396 - val_loss: 1.4054 - val_accuracy: 0.4767\n",
            "Epoch 4/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.4921 - accuracy: 0.3281\n",
            "Epoch 4: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.4507 - accuracy: 0.3709 - val_loss: 1.3491 - val_accuracy: 0.5700\n",
            "Epoch 5/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.3939 - accuracy: 0.4688\n",
            "Epoch 5: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.4009 - accuracy: 0.4166 - val_loss: 1.2875 - val_accuracy: 0.6152\n",
            "Epoch 6/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.4145 - accuracy: 0.4062\n",
            "Epoch 6: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.3563 - accuracy: 0.4362 - val_loss: 1.2235 - val_accuracy: 0.6116\n",
            "Epoch 7/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.3404 - accuracy: 0.4766\n",
            "Epoch 7: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.3183 - accuracy: 0.4645 - val_loss: 1.1643 - val_accuracy: 0.6260\n",
            "Epoch 8/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.3496 - accuracy: 0.4375\n",
            "Epoch 8: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.2779 - accuracy: 0.4834 - val_loss: 1.1105 - val_accuracy: 0.6525\n",
            "Epoch 9/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.2679 - accuracy: 0.5000\n",
            "Epoch 9: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.2457 - accuracy: 0.4992 - val_loss: 1.0624 - val_accuracy: 0.6633\n",
            "Epoch 10/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.2179 - accuracy: 0.5938\n",
            "Epoch 10: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.2102 - accuracy: 0.5154 - val_loss: 1.0151 - val_accuracy: 0.6734\n",
            "Epoch 11/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.2140 - accuracy: 0.4844\n",
            "Epoch 11: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.1796 - accuracy: 0.5286 - val_loss: 0.9780 - val_accuracy: 0.6777\n",
            "Epoch 12/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.2302 - accuracy: 0.4688\n",
            "Epoch 12: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1681 - accuracy: 0.5377 - val_loss: 0.9397 - val_accuracy: 0.6985\n",
            "Epoch 13/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.1291 - accuracy: 0.5547\n",
            "Epoch 13: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1503 - accuracy: 0.5444 - val_loss: 0.9160 - val_accuracy: 0.7107\n",
            "Epoch 14/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.1581 - accuracy: 0.5312\n",
            "Epoch 14: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.1263 - accuracy: 0.5463 - val_loss: 0.8885 - val_accuracy: 0.7114\n",
            "Epoch 15/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.0786 - accuracy: 0.6016\n",
            "Epoch 15: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0874 - accuracy: 0.5717 - val_loss: 0.8580 - val_accuracy: 0.7186\n",
            "Epoch 16/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.0431 - accuracy: 0.5703\n",
            "Epoch 16: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.0754 - accuracy: 0.5721 - val_loss: 0.8319 - val_accuracy: 0.7222\n",
            "Epoch 17/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9237 - accuracy: 0.6172\n",
            "Epoch 17: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0689 - accuracy: 0.5724 - val_loss: 0.8194 - val_accuracy: 0.7416\n",
            "Epoch 18/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.1486 - accuracy: 0.5547\n",
            "Epoch 18: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.0423 - accuracy: 0.5889 - val_loss: 0.7966 - val_accuracy: 0.7365\n",
            "Epoch 19/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.0695 - accuracy: 0.5859\n",
            "Epoch 19: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.0432 - accuracy: 0.5937 - val_loss: 0.7767 - val_accuracy: 0.7380\n",
            "Epoch 20/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.0971 - accuracy: 0.5703\n",
            "Epoch 20: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.0286 - accuracy: 0.6121 - val_loss: 0.7656 - val_accuracy: 0.7574\n",
            "Epoch 21/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.0496 - accuracy: 0.5391\n",
            "Epoch 21: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0135 - accuracy: 0.6025 - val_loss: 0.7512 - val_accuracy: 0.7602\n",
            "Epoch 22/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.0971 - accuracy: 0.6094\n",
            "Epoch 22: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.0050 - accuracy: 0.6147 - val_loss: 0.7355 - val_accuracy: 0.7674\n",
            "Epoch 23/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9068 - accuracy: 0.6016\n",
            "Epoch 23: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 1.0017 - accuracy: 0.6119 - val_loss: 0.7245 - val_accuracy: 0.7739\n",
            "Epoch 24/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9619 - accuracy: 0.6328\n",
            "Epoch 24: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9741 - accuracy: 0.6205 - val_loss: 0.7116 - val_accuracy: 0.7724\n",
            "Epoch 25/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.0092 - accuracy: 0.6094\n",
            "Epoch 25: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9690 - accuracy: 0.6305 - val_loss: 0.6993 - val_accuracy: 0.7803\n",
            "Epoch 26/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.0376 - accuracy: 0.6094\n",
            "Epoch 26: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.6389 - val_loss: 0.6935 - val_accuracy: 0.7803\n",
            "Epoch 27/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8399 - accuracy: 0.7109\n",
            "Epoch 27: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9461 - accuracy: 0.6418 - val_loss: 0.6852 - val_accuracy: 0.7911\n",
            "Epoch 28/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.0015 - accuracy: 0.5938\n",
            "Epoch 28: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9466 - accuracy: 0.6351 - val_loss: 0.6780 - val_accuracy: 0.8040\n",
            "Epoch 29/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8976 - accuracy: 0.6641\n",
            "Epoch 29: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9682 - accuracy: 0.6356 - val_loss: 0.6732 - val_accuracy: 0.7925\n",
            "Epoch 30/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8164 - accuracy: 0.6953\n",
            "Epoch 30: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.6466 - val_loss: 0.6639 - val_accuracy: 0.7954\n",
            "Epoch 31/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.1422 - accuracy: 0.5469\n",
            "Epoch 31: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9471 - accuracy: 0.6413 - val_loss: 0.6572 - val_accuracy: 0.7983\n",
            "Epoch 32/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8957 - accuracy: 0.6328\n",
            "Epoch 32: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9362 - accuracy: 0.6511 - val_loss: 0.6522 - val_accuracy: 0.8040\n",
            "Epoch 33/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9231 - accuracy: 0.6094\n",
            "Epoch 33: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9302 - accuracy: 0.6494 - val_loss: 0.6475 - val_accuracy: 0.8162\n",
            "Epoch 34/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9075 - accuracy: 0.6953\n",
            "Epoch 34: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9385 - accuracy: 0.6478 - val_loss: 0.6384 - val_accuracy: 0.8248\n",
            "Epoch 35/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9406 - accuracy: 0.6406\n",
            "Epoch 35: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9346 - accuracy: 0.6523 - val_loss: 0.6373 - val_accuracy: 0.8263\n",
            "Epoch 36/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9757 - accuracy: 0.5781\n",
            "Epoch 36: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9118 - accuracy: 0.6592 - val_loss: 0.6319 - val_accuracy: 0.8227\n",
            "Epoch 37/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8770 - accuracy: 0.6719\n",
            "Epoch 37: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9073 - accuracy: 0.6650 - val_loss: 0.6243 - val_accuracy: 0.8378\n",
            "Epoch 38/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7918 - accuracy: 0.6875\n",
            "Epoch 38: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9029 - accuracy: 0.6624 - val_loss: 0.6193 - val_accuracy: 0.8406\n",
            "Epoch 39/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8808 - accuracy: 0.6953\n",
            "Epoch 39: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.9037 - accuracy: 0.6715 - val_loss: 0.6105 - val_accuracy: 0.8370\n",
            "Epoch 40/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8727 - accuracy: 0.6719\n",
            "Epoch 40: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8844 - accuracy: 0.6772 - val_loss: 0.6096 - val_accuracy: 0.8342\n",
            "Epoch 41/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8645 - accuracy: 0.6953\n",
            "Epoch 41: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9062 - accuracy: 0.6679 - val_loss: 0.6065 - val_accuracy: 0.8464\n",
            "Epoch 42/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9196 - accuracy: 0.6094\n",
            "Epoch 42: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8777 - accuracy: 0.6784 - val_loss: 0.6004 - val_accuracy: 0.8421\n",
            "Epoch 43/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8044 - accuracy: 0.6875\n",
            "Epoch 43: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8650 - accuracy: 0.6870 - val_loss: 0.5906 - val_accuracy: 0.8428\n",
            "Epoch 44/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9284 - accuracy: 0.7109\n",
            "Epoch 44: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8835 - accuracy: 0.6758 - val_loss: 0.5859 - val_accuracy: 0.8421\n",
            "Epoch 45/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8230 - accuracy: 0.7344\n",
            "Epoch 45: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8926 - accuracy: 0.6729 - val_loss: 0.5895 - val_accuracy: 0.8378\n",
            "Epoch 46/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8793 - accuracy: 0.6406\n",
            "Epoch 46: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8913 - accuracy: 0.6652 - val_loss: 0.5843 - val_accuracy: 0.8478\n",
            "Epoch 47/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9086 - accuracy: 0.6875\n",
            "Epoch 47: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8625 - accuracy: 0.6849 - val_loss: 0.5794 - val_accuracy: 0.8449\n",
            "Epoch 48/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9325 - accuracy: 0.6875\n",
            "Epoch 48: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8778 - accuracy: 0.6805 - val_loss: 0.5783 - val_accuracy: 0.8485\n",
            "Epoch 49/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9389 - accuracy: 0.6172\n",
            "Epoch 49: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8701 - accuracy: 0.6726 - val_loss: 0.5778 - val_accuracy: 0.8478\n",
            "Epoch 50/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7979 - accuracy: 0.7500\n",
            "Epoch 50: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8683 - accuracy: 0.6865 - val_loss: 0.5720 - val_accuracy: 0.8464\n",
            "Epoch 51/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9508 - accuracy: 0.6484\n",
            "Epoch 51: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8485 - accuracy: 0.6963 - val_loss: 0.5554 - val_accuracy: 0.8449\n",
            "Epoch 52/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6962 - accuracy: 0.7734\n",
            "Epoch 52: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8823 - accuracy: 0.6782 - val_loss: 0.5671 - val_accuracy: 0.8442\n",
            "Epoch 53/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7374 - accuracy: 0.7266\n",
            "Epoch 53: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8523 - accuracy: 0.6880 - val_loss: 0.5573 - val_accuracy: 0.8442\n",
            "Epoch 54/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7553 - accuracy: 0.7109\n",
            "Epoch 54: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8640 - accuracy: 0.6839 - val_loss: 0.5589 - val_accuracy: 0.8442\n",
            "Epoch 55/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8103 - accuracy: 0.7266\n",
            "Epoch 55: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8518 - accuracy: 0.6880 - val_loss: 0.5554 - val_accuracy: 0.8478\n",
            "Epoch 56/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9289 - accuracy: 0.6953\n",
            "Epoch 56: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8679 - accuracy: 0.6868 - val_loss: 0.5581 - val_accuracy: 0.8435\n",
            "Epoch 57/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8572 - accuracy: 0.7188\n",
            "Epoch 57: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8373 - accuracy: 0.6911 - val_loss: 0.5548 - val_accuracy: 0.8428\n",
            "Epoch 58/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9236 - accuracy: 0.6406\n",
            "Epoch 58: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8577 - accuracy: 0.6884 - val_loss: 0.5536 - val_accuracy: 0.8413\n",
            "Epoch 59/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.1108 - accuracy: 0.6016\n",
            "Epoch 59: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8563 - accuracy: 0.6887 - val_loss: 0.5448 - val_accuracy: 0.8471\n",
            "Epoch 60/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7774 - accuracy: 0.6953\n",
            "Epoch 60: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8502 - accuracy: 0.6875 - val_loss: 0.5489 - val_accuracy: 0.8385\n",
            "Epoch 61/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7915 - accuracy: 0.6875\n",
            "Epoch 61: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8334 - accuracy: 0.6868 - val_loss: 0.5407 - val_accuracy: 0.8449\n",
            "Epoch 62/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8526 - accuracy: 0.7109\n",
            "Epoch 62: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8357 - accuracy: 0.6939 - val_loss: 0.5279 - val_accuracy: 0.8550\n",
            "Epoch 63/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8305 - accuracy: 0.7031\n",
            "Epoch 63: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8328 - accuracy: 0.6927 - val_loss: 0.5370 - val_accuracy: 0.8449\n",
            "Epoch 64/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7819 - accuracy: 0.6953\n",
            "Epoch 64: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8477 - accuracy: 0.6889 - val_loss: 0.5306 - val_accuracy: 0.8514\n",
            "Epoch 65/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7655 - accuracy: 0.7500\n",
            "Epoch 65: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8212 - accuracy: 0.6994 - val_loss: 0.5307 - val_accuracy: 0.8571\n",
            "Epoch 66/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8523 - accuracy: 0.6797\n",
            "Epoch 66: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8424 - accuracy: 0.6963 - val_loss: 0.5301 - val_accuracy: 0.8485\n",
            "Epoch 67/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8972 - accuracy: 0.7344\n",
            "Epoch 67: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8424 - accuracy: 0.6994 - val_loss: 0.5286 - val_accuracy: 0.8500\n",
            "Epoch 68/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 1.0345 - accuracy: 0.6094\n",
            "Epoch 68: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8323 - accuracy: 0.6942 - val_loss: 0.5259 - val_accuracy: 0.8435\n",
            "Epoch 69/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7909 - accuracy: 0.6797\n",
            "Epoch 69: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8286 - accuracy: 0.6971 - val_loss: 0.5222 - val_accuracy: 0.8471\n",
            "Epoch 70/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9150 - accuracy: 0.7031\n",
            "Epoch 70: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8411 - accuracy: 0.6992 - val_loss: 0.5236 - val_accuracy: 0.8507\n",
            "Epoch 71/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8836 - accuracy: 0.6562\n",
            "Epoch 71: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8293 - accuracy: 0.6947 - val_loss: 0.5229 - val_accuracy: 0.8557\n",
            "Epoch 72/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7510 - accuracy: 0.7422\n",
            "Epoch 72: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8381 - accuracy: 0.6987 - val_loss: 0.5249 - val_accuracy: 0.8492\n",
            "Epoch 73/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7102 - accuracy: 0.7266\n",
            "Epoch 73: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8201 - accuracy: 0.7040 - val_loss: 0.5216 - val_accuracy: 0.8471\n",
            "Epoch 74/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8953 - accuracy: 0.7031\n",
            "Epoch 74: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8159 - accuracy: 0.7073 - val_loss: 0.5115 - val_accuracy: 0.8543\n",
            "Epoch 75/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8596 - accuracy: 0.6406\n",
            "Epoch 75: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8114 - accuracy: 0.7061 - val_loss: 0.5095 - val_accuracy: 0.8557\n",
            "Epoch 76/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7886 - accuracy: 0.6953\n",
            "Epoch 76: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8386 - accuracy: 0.6987 - val_loss: 0.5153 - val_accuracy: 0.8500\n",
            "Epoch 77/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8755 - accuracy: 0.6797\n",
            "Epoch 77: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.7107 - val_loss: 0.5102 - val_accuracy: 0.8543\n",
            "Epoch 78/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9010 - accuracy: 0.6250\n",
            "Epoch 78: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8132 - accuracy: 0.7002 - val_loss: 0.5161 - val_accuracy: 0.8528\n",
            "Epoch 79/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7804 - accuracy: 0.6562\n",
            "Epoch 79: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8210 - accuracy: 0.7073 - val_loss: 0.5094 - val_accuracy: 0.8550\n",
            "Epoch 80/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8686 - accuracy: 0.7031\n",
            "Epoch 80: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8088 - accuracy: 0.7069 - val_loss: 0.5098 - val_accuracy: 0.8564\n",
            "Epoch 81/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7896 - accuracy: 0.7188\n",
            "Epoch 81: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7932 - accuracy: 0.7150 - val_loss: 0.5022 - val_accuracy: 0.8543\n",
            "Epoch 82/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8148 - accuracy: 0.7266\n",
            "Epoch 82: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8149 - accuracy: 0.7064 - val_loss: 0.5042 - val_accuracy: 0.8658\n",
            "Epoch 83/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8115 - accuracy: 0.6797\n",
            "Epoch 83: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7975 - accuracy: 0.7088 - val_loss: 0.5099 - val_accuracy: 0.8507\n",
            "Epoch 84/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8844 - accuracy: 0.6484\n",
            "Epoch 84: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7983 - accuracy: 0.7143 - val_loss: 0.5074 - val_accuracy: 0.8485\n",
            "Epoch 85/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7570 - accuracy: 0.7109\n",
            "Epoch 85: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7969 - accuracy: 0.7117 - val_loss: 0.5036 - val_accuracy: 0.8543\n",
            "Epoch 86/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9270 - accuracy: 0.6797\n",
            "Epoch 86: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8176 - accuracy: 0.7054 - val_loss: 0.5026 - val_accuracy: 0.8521\n",
            "Epoch 87/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7251 - accuracy: 0.7109\n",
            "Epoch 87: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7977 - accuracy: 0.7143 - val_loss: 0.4948 - val_accuracy: 0.8622\n",
            "Epoch 88/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7584 - accuracy: 0.7734\n",
            "Epoch 88: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8151 - accuracy: 0.7179 - val_loss: 0.4924 - val_accuracy: 0.8643\n",
            "Epoch 89/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8031 - accuracy: 0.7578\n",
            "Epoch 89: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8309 - accuracy: 0.6990 - val_loss: 0.4981 - val_accuracy: 0.8650\n",
            "Epoch 90/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7433 - accuracy: 0.7500\n",
            "Epoch 90: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7970 - accuracy: 0.7112 - val_loss: 0.4926 - val_accuracy: 0.8643\n",
            "Epoch 91/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7443 - accuracy: 0.7500\n",
            "Epoch 91: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7798 - accuracy: 0.7241 - val_loss: 0.4861 - val_accuracy: 0.8607\n",
            "Epoch 92/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7214 - accuracy: 0.7109\n",
            "Epoch 92: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8012 - accuracy: 0.7138 - val_loss: 0.4971 - val_accuracy: 0.8550\n",
            "Epoch 93/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8062 - accuracy: 0.7422\n",
            "Epoch 93: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8153 - accuracy: 0.7018 - val_loss: 0.5025 - val_accuracy: 0.8586\n",
            "Epoch 94/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8220 - accuracy: 0.7266\n",
            "Epoch 94: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7880 - accuracy: 0.7203 - val_loss: 0.4946 - val_accuracy: 0.8600\n",
            "Epoch 95/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7875 - accuracy: 0.6797\n",
            "Epoch 95: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8068 - accuracy: 0.7085 - val_loss: 0.4890 - val_accuracy: 0.8665\n",
            "Epoch 96/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7763 - accuracy: 0.6875\n",
            "Epoch 96: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7972 - accuracy: 0.7164 - val_loss: 0.4875 - val_accuracy: 0.8629\n",
            "Epoch 97/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8815 - accuracy: 0.7344\n",
            "Epoch 97: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7866 - accuracy: 0.7169 - val_loss: 0.4874 - val_accuracy: 0.8622\n",
            "Epoch 98/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6492 - accuracy: 0.8203\n",
            "Epoch 98: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7850 - accuracy: 0.7236 - val_loss: 0.4864 - val_accuracy: 0.8629\n",
            "Epoch 99/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7403 - accuracy: 0.7422\n",
            "Epoch 99: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8076 - accuracy: 0.7100 - val_loss: 0.4963 - val_accuracy: 0.8636\n",
            "Epoch 100/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.5597 - accuracy: 0.7734\n",
            "Epoch 100: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7986 - accuracy: 0.7054 - val_loss: 0.4896 - val_accuracy: 0.8607\n",
            "Epoch 101/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6802 - accuracy: 0.7266\n",
            "Epoch 101: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8198 - accuracy: 0.7054 - val_loss: 0.5009 - val_accuracy: 0.8536\n",
            "Epoch 102/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7266 - accuracy: 0.6953\n",
            "Epoch 102: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7798 - accuracy: 0.7207 - val_loss: 0.4881 - val_accuracy: 0.8643\n",
            "Epoch 103/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.5977 - accuracy: 0.8047\n",
            "Epoch 103: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7859 - accuracy: 0.7203 - val_loss: 0.4861 - val_accuracy: 0.8586\n",
            "Epoch 104/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8012 - accuracy: 0.6953\n",
            "Epoch 104: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7924 - accuracy: 0.7131 - val_loss: 0.4928 - val_accuracy: 0.8622\n",
            "Epoch 105/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7190 - accuracy: 0.7109\n",
            "Epoch 105: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7851 - accuracy: 0.7193 - val_loss: 0.4808 - val_accuracy: 0.8686\n",
            "Epoch 106/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9339 - accuracy: 0.6953\n",
            "Epoch 106: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7601 - accuracy: 0.7196 - val_loss: 0.4801 - val_accuracy: 0.8715\n",
            "Epoch 107/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7619 - accuracy: 0.7266\n",
            "Epoch 107: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7779 - accuracy: 0.7188 - val_loss: 0.4774 - val_accuracy: 0.8622\n",
            "Epoch 108/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8302 - accuracy: 0.7188\n",
            "Epoch 108: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.8148 - accuracy: 0.7009 - val_loss: 0.4959 - val_accuracy: 0.8636\n",
            "Epoch 109/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7610 - accuracy: 0.6875\n",
            "Epoch 109: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7692 - accuracy: 0.7215 - val_loss: 0.4892 - val_accuracy: 0.8586\n",
            "Epoch 110/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7038 - accuracy: 0.7109\n",
            "Epoch 110: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7578 - accuracy: 0.7289 - val_loss: 0.4706 - val_accuracy: 0.8665\n",
            "Epoch 111/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6674 - accuracy: 0.7500\n",
            "Epoch 111: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7726 - accuracy: 0.7172 - val_loss: 0.4774 - val_accuracy: 0.8693\n",
            "Epoch 112/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7916 - accuracy: 0.7344\n",
            "Epoch 112: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8049 - accuracy: 0.7088 - val_loss: 0.4808 - val_accuracy: 0.8672\n",
            "Epoch 113/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6337 - accuracy: 0.7969\n",
            "Epoch 113: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7761 - accuracy: 0.7210 - val_loss: 0.4799 - val_accuracy: 0.8607\n",
            "Epoch 114/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7940 - accuracy: 0.7500\n",
            "Epoch 114: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7698 - accuracy: 0.7274 - val_loss: 0.4757 - val_accuracy: 0.8693\n",
            "Epoch 115/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9742 - accuracy: 0.6328\n",
            "Epoch 115: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7699 - accuracy: 0.7263 - val_loss: 0.4768 - val_accuracy: 0.8658\n",
            "Epoch 116/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8766 - accuracy: 0.7266\n",
            "Epoch 116: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7950 - accuracy: 0.7143 - val_loss: 0.4873 - val_accuracy: 0.8607\n",
            "Epoch 117/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8660 - accuracy: 0.6562\n",
            "Epoch 117: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7771 - accuracy: 0.7207 - val_loss: 0.4766 - val_accuracy: 0.8693\n",
            "Epoch 118/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7154 - accuracy: 0.7500\n",
            "Epoch 118: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7784 - accuracy: 0.7205 - val_loss: 0.4747 - val_accuracy: 0.8722\n",
            "Epoch 119/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9163 - accuracy: 0.6953\n",
            "Epoch 119: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7902 - accuracy: 0.7246 - val_loss: 0.4850 - val_accuracy: 0.8665\n",
            "Epoch 120/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7353 - accuracy: 0.7500\n",
            "Epoch 120: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7573 - accuracy: 0.7298 - val_loss: 0.4693 - val_accuracy: 0.8679\n",
            "Epoch 121/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7460 - accuracy: 0.6875\n",
            "Epoch 121: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7699 - accuracy: 0.7289 - val_loss: 0.4751 - val_accuracy: 0.8636\n",
            "Epoch 122/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7626 - accuracy: 0.7344\n",
            "Epoch 122: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7688 - accuracy: 0.7246 - val_loss: 0.4756 - val_accuracy: 0.8693\n",
            "Epoch 123/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6603 - accuracy: 0.7422\n",
            "Epoch 123: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7753 - accuracy: 0.7212 - val_loss: 0.4730 - val_accuracy: 0.8679\n",
            "Epoch 124/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8497 - accuracy: 0.6641\n",
            "Epoch 124: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7744 - accuracy: 0.7243 - val_loss: 0.4756 - val_accuracy: 0.8679\n",
            "Epoch 125/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6335 - accuracy: 0.8125\n",
            "Epoch 125: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7568 - accuracy: 0.7310 - val_loss: 0.4767 - val_accuracy: 0.8629\n",
            "Epoch 126/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9163 - accuracy: 0.7422\n",
            "Epoch 126: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7746 - accuracy: 0.7148 - val_loss: 0.4658 - val_accuracy: 0.8672\n",
            "Epoch 127/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7890 - accuracy: 0.7500\n",
            "Epoch 127: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7642 - accuracy: 0.7205 - val_loss: 0.4672 - val_accuracy: 0.8672\n",
            "Epoch 128/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6913 - accuracy: 0.7734\n",
            "Epoch 128: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7599 - accuracy: 0.7263 - val_loss: 0.4676 - val_accuracy: 0.8658\n",
            "Epoch 129/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7619 - accuracy: 0.7188\n",
            "Epoch 129: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7639 - accuracy: 0.7301 - val_loss: 0.4647 - val_accuracy: 0.8658\n",
            "Epoch 130/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7380 - accuracy: 0.7891\n",
            "Epoch 130: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7466 - accuracy: 0.7277 - val_loss: 0.4674 - val_accuracy: 0.8672\n",
            "Epoch 131/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6901 - accuracy: 0.7578\n",
            "Epoch 131: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7782 - accuracy: 0.7260 - val_loss: 0.4688 - val_accuracy: 0.8729\n",
            "Epoch 132/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7526 - accuracy: 0.7500\n",
            "Epoch 132: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7686 - accuracy: 0.7229 - val_loss: 0.4647 - val_accuracy: 0.8679\n",
            "Epoch 133/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6963 - accuracy: 0.7500\n",
            "Epoch 133: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7647 - accuracy: 0.7227 - val_loss: 0.4668 - val_accuracy: 0.8658\n",
            "Epoch 134/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7686 - accuracy: 0.6953\n",
            "Epoch 134: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7733 - accuracy: 0.7172 - val_loss: 0.4659 - val_accuracy: 0.8672\n",
            "Epoch 135/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8543 - accuracy: 0.7422\n",
            "Epoch 135: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7748 - accuracy: 0.7291 - val_loss: 0.4667 - val_accuracy: 0.8672\n",
            "Epoch 136/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7250 - accuracy: 0.7266\n",
            "Epoch 136: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 0.7253 - val_loss: 0.4696 - val_accuracy: 0.8658\n",
            "Epoch 137/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6624 - accuracy: 0.7812\n",
            "Epoch 137: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7518 - accuracy: 0.7279 - val_loss: 0.4615 - val_accuracy: 0.8643\n",
            "Epoch 138/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7661 - accuracy: 0.7500\n",
            "Epoch 138: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7697 - accuracy: 0.7272 - val_loss: 0.4664 - val_accuracy: 0.8693\n",
            "Epoch 139/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7344\n",
            "Epoch 139: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7687 - accuracy: 0.7219 - val_loss: 0.4687 - val_accuracy: 0.8744\n",
            "Epoch 140/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7750 - accuracy: 0.7266\n",
            "Epoch 140: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7855 - accuracy: 0.7222 - val_loss: 0.4734 - val_accuracy: 0.8679\n",
            "Epoch 141/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6266 - accuracy: 0.8047\n",
            "Epoch 141: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7518 - accuracy: 0.7361 - val_loss: 0.4737 - val_accuracy: 0.8693\n",
            "Epoch 142/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8167 - accuracy: 0.6875\n",
            "Epoch 142: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7620 - accuracy: 0.7243 - val_loss: 0.4630 - val_accuracy: 0.8679\n",
            "Epoch 143/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8691 - accuracy: 0.7578\n",
            "Epoch 143: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.7289 - val_loss: 0.4575 - val_accuracy: 0.8722\n",
            "Epoch 144/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7044 - accuracy: 0.8203\n",
            "Epoch 144: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7468 - accuracy: 0.7361 - val_loss: 0.4528 - val_accuracy: 0.8758\n",
            "Epoch 145/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7109 - accuracy: 0.7656\n",
            "Epoch 145: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7736 - accuracy: 0.7306 - val_loss: 0.4708 - val_accuracy: 0.8615\n",
            "Epoch 146/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7141 - accuracy: 0.7031\n",
            "Epoch 146: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7521 - accuracy: 0.7397 - val_loss: 0.4629 - val_accuracy: 0.8722\n",
            "Epoch 147/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6252 - accuracy: 0.7891\n",
            "Epoch 147: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7464 - accuracy: 0.7349 - val_loss: 0.4638 - val_accuracy: 0.8658\n",
            "Epoch 148/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7987 - accuracy: 0.7500\n",
            "Epoch 148: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7530 - accuracy: 0.7243 - val_loss: 0.4696 - val_accuracy: 0.8665\n",
            "Epoch 149/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6702 - accuracy: 0.7500\n",
            "Epoch 149: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7259 - accuracy: 0.7432 - val_loss: 0.4581 - val_accuracy: 0.8636\n",
            "Epoch 150/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9124 - accuracy: 0.7031\n",
            "Epoch 150: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7505 - accuracy: 0.7408 - val_loss: 0.4565 - val_accuracy: 0.8701\n",
            "Epoch 151/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7933 - accuracy: 0.7109\n",
            "Epoch 151: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.7322 - val_loss: 0.4605 - val_accuracy: 0.8650\n",
            "Epoch 152/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6869 - accuracy: 0.7422\n",
            "Epoch 152: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7541 - accuracy: 0.7274 - val_loss: 0.4636 - val_accuracy: 0.8658\n",
            "Epoch 153/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6939 - accuracy: 0.7578\n",
            "Epoch 153: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.7339 - val_loss: 0.4596 - val_accuracy: 0.8693\n",
            "Epoch 154/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7812\n",
            "Epoch 154: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7418 - accuracy: 0.7313 - val_loss: 0.4591 - val_accuracy: 0.8643\n",
            "Epoch 155/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8062 - accuracy: 0.7109\n",
            "Epoch 155: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.7265 - val_loss: 0.4582 - val_accuracy: 0.8693\n",
            "Epoch 156/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7179 - accuracy: 0.7656\n",
            "Epoch 156: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.7267 - val_loss: 0.4582 - val_accuracy: 0.8679\n",
            "Epoch 157/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6970 - accuracy: 0.7734\n",
            "Epoch 157: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7682 - accuracy: 0.7263 - val_loss: 0.4667 - val_accuracy: 0.8729\n",
            "Epoch 158/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7422 - accuracy: 0.7188\n",
            "Epoch 158: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.7413 - val_loss: 0.4605 - val_accuracy: 0.8715\n",
            "Epoch 159/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6369 - accuracy: 0.7734\n",
            "Epoch 159: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7391 - accuracy: 0.7392 - val_loss: 0.4513 - val_accuracy: 0.8830\n",
            "Epoch 160/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7055 - accuracy: 0.7109\n",
            "Epoch 160: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7453 - accuracy: 0.7308 - val_loss: 0.4616 - val_accuracy: 0.8737\n",
            "Epoch 161/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7325 - accuracy: 0.7812\n",
            "Epoch 161: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7564 - accuracy: 0.7341 - val_loss: 0.4532 - val_accuracy: 0.8693\n",
            "Epoch 162/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8279 - accuracy: 0.7188\n",
            "Epoch 162: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7654 - accuracy: 0.7193 - val_loss: 0.4677 - val_accuracy: 0.8593\n",
            "Epoch 163/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8169 - accuracy: 0.7656\n",
            "Epoch 163: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7496 - accuracy: 0.7361 - val_loss: 0.4561 - val_accuracy: 0.8744\n",
            "Epoch 164/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8271 - accuracy: 0.7031\n",
            "Epoch 164: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7648 - accuracy: 0.7270 - val_loss: 0.4568 - val_accuracy: 0.8715\n",
            "Epoch 165/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7916 - accuracy: 0.7656\n",
            "Epoch 165: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7467 - accuracy: 0.7344 - val_loss: 0.4610 - val_accuracy: 0.8672\n",
            "Epoch 166/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7022 - accuracy: 0.7422\n",
            "Epoch 166: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7590 - accuracy: 0.7358 - val_loss: 0.4687 - val_accuracy: 0.8658\n",
            "Epoch 167/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6290 - accuracy: 0.7422\n",
            "Epoch 167: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7416 - accuracy: 0.7430 - val_loss: 0.4569 - val_accuracy: 0.8665\n",
            "Epoch 168/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6799 - accuracy: 0.7812\n",
            "Epoch 168: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7419 - accuracy: 0.7353 - val_loss: 0.4521 - val_accuracy: 0.8787\n",
            "Epoch 169/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6852 - accuracy: 0.7422\n",
            "Epoch 169: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7403 - accuracy: 0.7265 - val_loss: 0.4574 - val_accuracy: 0.8658\n",
            "Epoch 170/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.9384 - accuracy: 0.6641\n",
            "Epoch 170: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7433 - accuracy: 0.7353 - val_loss: 0.4609 - val_accuracy: 0.8701\n",
            "Epoch 171/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7847 - accuracy: 0.7344\n",
            "Epoch 171: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7289 - accuracy: 0.7375 - val_loss: 0.4550 - val_accuracy: 0.8679\n",
            "Epoch 172/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.5844 - accuracy: 0.7656\n",
            "Epoch 172: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7375 - accuracy: 0.7375 - val_loss: 0.4647 - val_accuracy: 0.8658\n",
            "Epoch 173/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6949 - accuracy: 0.7656\n",
            "Epoch 173: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.7322 - val_loss: 0.4569 - val_accuracy: 0.8737\n",
            "Epoch 174/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7845 - accuracy: 0.6797\n",
            "Epoch 174: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7494 - accuracy: 0.7298 - val_loss: 0.4586 - val_accuracy: 0.8650\n",
            "Epoch 175/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.5604 - accuracy: 0.8047\n",
            "Epoch 175: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7327 - accuracy: 0.7387 - val_loss: 0.4680 - val_accuracy: 0.8643\n",
            "Epoch 176/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7049 - accuracy: 0.6953\n",
            "Epoch 176: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7462 - accuracy: 0.7337 - val_loss: 0.4560 - val_accuracy: 0.8658\n",
            "Epoch 177/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7247 - accuracy: 0.7578\n",
            "Epoch 177: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7239 - accuracy: 0.7440 - val_loss: 0.4554 - val_accuracy: 0.8643\n",
            "Epoch 178/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6835 - accuracy: 0.7031\n",
            "Epoch 178: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7341 - val_loss: 0.4505 - val_accuracy: 0.8679\n",
            "Epoch 179/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7656\n",
            "Epoch 179: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7298 - accuracy: 0.7397 - val_loss: 0.4472 - val_accuracy: 0.8701\n",
            "Epoch 180/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7854 - accuracy: 0.7812\n",
            "Epoch 180: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7365 - val_loss: 0.4587 - val_accuracy: 0.8622\n",
            "Epoch 181/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6534 - accuracy: 0.7422\n",
            "Epoch 181: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7436 - accuracy: 0.7368 - val_loss: 0.4606 - val_accuracy: 0.8579\n",
            "Epoch 182/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6389 - accuracy: 0.7656\n",
            "Epoch 182: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7314 - accuracy: 0.7320 - val_loss: 0.4534 - val_accuracy: 0.8679\n",
            "Epoch 183/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6654 - accuracy: 0.7266\n",
            "Epoch 183: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7339 - val_loss: 0.4589 - val_accuracy: 0.8701\n",
            "Epoch 184/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8454 - accuracy: 0.6719\n",
            "Epoch 184: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.7375 - val_loss: 0.4434 - val_accuracy: 0.8801\n",
            "Epoch 185/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7091 - accuracy: 0.7578\n",
            "Epoch 185: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7390 - accuracy: 0.7408 - val_loss: 0.4551 - val_accuracy: 0.8722\n",
            "Epoch 186/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6956 - accuracy: 0.7188\n",
            "Epoch 186: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.7318 - val_loss: 0.4482 - val_accuracy: 0.8816\n",
            "Epoch 187/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6521 - accuracy: 0.7578\n",
            "Epoch 187: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7424 - accuracy: 0.7277 - val_loss: 0.4512 - val_accuracy: 0.8772\n",
            "Epoch 188/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8198 - accuracy: 0.6875\n",
            "Epoch 188: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7439 - accuracy: 0.7370 - val_loss: 0.4424 - val_accuracy: 0.8765\n",
            "Epoch 189/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7600 - accuracy: 0.7656\n",
            "Epoch 189: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.7351 - val_loss: 0.4583 - val_accuracy: 0.8751\n",
            "Epoch 190/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7356 - accuracy: 0.7031\n",
            "Epoch 190: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7286 - accuracy: 0.7397 - val_loss: 0.4586 - val_accuracy: 0.8751\n",
            "Epoch 191/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.5759 - accuracy: 0.8359\n",
            "Epoch 191: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7331 - accuracy: 0.7430 - val_loss: 0.4592 - val_accuracy: 0.8643\n",
            "Epoch 192/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.5095 - accuracy: 0.8281\n",
            "Epoch 192: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7287 - accuracy: 0.7461 - val_loss: 0.4616 - val_accuracy: 0.8708\n",
            "Epoch 193/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7724 - accuracy: 0.7031\n",
            "Epoch 193: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7260 - accuracy: 0.7502 - val_loss: 0.4514 - val_accuracy: 0.8794\n",
            "Epoch 194/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6224 - accuracy: 0.8281\n",
            "Epoch 194: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7219 - accuracy: 0.7406 - val_loss: 0.4525 - val_accuracy: 0.8679\n",
            "Epoch 195/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6956 - accuracy: 0.7578\n",
            "Epoch 195: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.7373 - val_loss: 0.4561 - val_accuracy: 0.8686\n",
            "Epoch 196/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7448 - accuracy: 0.7266\n",
            "Epoch 196: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7301 - accuracy: 0.7428 - val_loss: 0.4521 - val_accuracy: 0.8715\n",
            "Epoch 197/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6852 - accuracy: 0.7188\n",
            "Epoch 197: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7348 - accuracy: 0.7325 - val_loss: 0.4574 - val_accuracy: 0.8686\n",
            "Epoch 198/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.5538 - accuracy: 0.8438\n",
            "Epoch 198: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7339 - accuracy: 0.7461 - val_loss: 0.4434 - val_accuracy: 0.8715\n",
            "Epoch 199/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7544 - accuracy: 0.7188\n",
            "Epoch 199: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7380 - accuracy: 0.7341 - val_loss: 0.4517 - val_accuracy: 0.8758\n",
            "Epoch 200/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6534 - accuracy: 0.7656\n",
            "Epoch 200: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.7478 - val_loss: 0.4595 - val_accuracy: 0.8658\n",
            "Epoch 201/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7310 - accuracy: 0.7422\n",
            "Epoch 201: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7290 - accuracy: 0.7406 - val_loss: 0.4378 - val_accuracy: 0.8808\n",
            "Epoch 202/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6975 - accuracy: 0.7734\n",
            "Epoch 202: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.7499 - val_loss: 0.4541 - val_accuracy: 0.8816\n",
            "Epoch 203/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6569 - accuracy: 0.7188\n",
            "Epoch 203: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.7504 - val_loss: 0.4376 - val_accuracy: 0.8873\n",
            "Epoch 204/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7007 - accuracy: 0.7188\n",
            "Epoch 204: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7248 - accuracy: 0.7416 - val_loss: 0.4556 - val_accuracy: 0.8593\n",
            "Epoch 205/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6912 - accuracy: 0.7422\n",
            "Epoch 205: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7161 - accuracy: 0.7480 - val_loss: 0.4406 - val_accuracy: 0.8751\n",
            "Epoch 206/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7196 - accuracy: 0.7344\n",
            "Epoch 206: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.7464 - val_loss: 0.4530 - val_accuracy: 0.8715\n",
            "Epoch 207/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7751 - accuracy: 0.7188\n",
            "Epoch 207: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7319 - accuracy: 0.7377 - val_loss: 0.4418 - val_accuracy: 0.8808\n",
            "Epoch 208/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7960 - accuracy: 0.7031\n",
            "Epoch 208: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7438 - accuracy: 0.7279 - val_loss: 0.4562 - val_accuracy: 0.8629\n",
            "Epoch 209/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7509 - accuracy: 0.7500\n",
            "Epoch 209: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7498 - accuracy: 0.7401 - val_loss: 0.4597 - val_accuracy: 0.8693\n",
            "Epoch 210/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8459 - accuracy: 0.6641\n",
            "Epoch 210: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7267 - accuracy: 0.7368 - val_loss: 0.4456 - val_accuracy: 0.8758\n",
            "Epoch 211/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6725 - accuracy: 0.7656\n",
            "Epoch 211: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7276 - accuracy: 0.7397 - val_loss: 0.4552 - val_accuracy: 0.8693\n",
            "Epoch 212/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7188\n",
            "Epoch 212: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7316 - accuracy: 0.7444 - val_loss: 0.4534 - val_accuracy: 0.8686\n",
            "Epoch 213/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7702 - accuracy: 0.7031\n",
            "Epoch 213: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7277 - accuracy: 0.7425 - val_loss: 0.4610 - val_accuracy: 0.8622\n",
            "Epoch 214/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6076 - accuracy: 0.7969\n",
            "Epoch 214: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7392 - accuracy: 0.7337 - val_loss: 0.4701 - val_accuracy: 0.8564\n",
            "Epoch 215/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6848 - accuracy: 0.7500\n",
            "Epoch 215: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7253 - accuracy: 0.7406 - val_loss: 0.4633 - val_accuracy: 0.8693\n",
            "Epoch 216/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7366 - accuracy: 0.7500\n",
            "Epoch 216: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7386 - accuracy: 0.7353 - val_loss: 0.4561 - val_accuracy: 0.8729\n",
            "Epoch 217/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7277 - accuracy: 0.7188\n",
            "Epoch 217: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7262 - accuracy: 0.7425 - val_loss: 0.4539 - val_accuracy: 0.8679\n",
            "Epoch 218/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7580 - accuracy: 0.6875\n",
            "Epoch 218: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7235 - accuracy: 0.7397 - val_loss: 0.4524 - val_accuracy: 0.8636\n",
            "Epoch 219/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6405 - accuracy: 0.7734\n",
            "Epoch 219: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7452 - accuracy: 0.7363 - val_loss: 0.4636 - val_accuracy: 0.8600\n",
            "Epoch 220/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.7731 - accuracy: 0.7344\n",
            "Epoch 220: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.7437 - val_loss: 0.4560 - val_accuracy: 0.8658\n",
            "Epoch 221/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.6549 - accuracy: 0.7812\n",
            "Epoch 221: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7341 - accuracy: 0.7468 - val_loss: 0.4574 - val_accuracy: 0.8679\n",
            "Epoch 222/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8661 - accuracy: 0.7266\n",
            "Epoch 222: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.7480 - val_loss: 0.4509 - val_accuracy: 0.8650\n",
            "Epoch 223/1000\n",
            " 1/33 [..............................] - ETA: 0s - loss: 0.8897 - accuracy: 0.6875\n",
            "Epoch 223: saving model to hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.7312 - accuracy: 0.7387 - val_loss: 0.4551 - val_accuracy: 0.8672\n",
            "Epoch 223: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x197e0b30610>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvb2Y299hE3",
        "outputId": "59eb3185-2e37-4b9e-bc9d-ab1b8ac29b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 800us/step - loss: 0.4551 - accuracy: 0.8672\n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RBkmDeUW9hE4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unexpected exception formatting exception. Falling back to standard exception\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Temp\\ipykernel_9392\\1559147557.py\", line 2, in <module>\n",
            "    model = keras.models.load_model(model_save_path,encoding='latin1')\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\neore\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\saving\\saving_api.py\", line 212, in load_model\n",
            "    return legacy_sm_saving_lib.load_model(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\neore\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"C:\\Users\\neore\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
            "    filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: load_model() got an unexpected keyword argument 'encoding'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1030, in format_exception_as_a_whole\n",
            "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1127, in get_records\n",
            "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
            "    yield from collapse_repeated(\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
            "    yield from map(mapper, original_group)\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
            "    return cls(f, options)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
            "    self.executing = Source.executing(frame_or_tb)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\executing\\executing.py\", line 378, in executing\n",
            "    assert_(new_stmts <= stmts)\n",
            "  File \"C:\\Users\\neore\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\executing\\executing.py\", line 154, in assert_\n",
            "    raise AssertionError(str(message))\n",
            "AssertionError\n"
          ]
        }
      ],
      "source": [
        "# Loading the saved model\n",
        "model = keras.models.load_model(model_save_path,encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz9Tb0I9hE4",
        "outputId": "1c3b3528-54ae-4ee2-ab04-77429211cbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "[0.03369437 0.11771096 0.70654976 0.07572392 0.06632102]\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 0s 581us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       410\n",
            "           1       0.84      0.83      0.83       384\n",
            "           2       0.79      0.98      0.87       328\n",
            "           3       0.79      0.53      0.63       145\n",
            "           4       0.91      0.67      0.78       126\n",
            "\n",
            "    accuracy                           0.87      1393\n",
            "   macro avg       0.86      0.80      0.82      1393\n",
            "weighted avg       0.87      0.87      0.86      1393\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfuK8Y59hE6",
        "outputId": "a4ca585c-b5d5-4244-8291-8674063209bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\neore\\AppData\\Local\\Temp\\tmp9sxdnyxs\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\neore\\AppData\\Local\\Temp\\tmp9sxdnyxs\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6588"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform model (quantization)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CHBPBXdx9hE6"
      },
      "source": [
        "# Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mGAzLocO9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oQuDK8YS9hE7"
      },
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2_ixAf_l9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FoAnuc9hE7",
        "outputId": "91f18257-8d8b-4ef3-c558-e9b5f94fabbf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 0 ns\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vONjp19J9hE8",
        "outputId": "77205e24-fd00-42c4-f7b6-e06e527c2cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.03369436 0.11771097 0.70654976 0.07572389 0.06632102]\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "keypoint_classification_EN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
